{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bf88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2503c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import json\n",
    "from data_transfer_utility.application import DataTransferUtility\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from lifelines.utils import concordance_index\n",
    "import random\n",
    "import copy\n",
    "from cryptography.fernet import Fernet\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "from datetime import date,timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "today_date = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffde30-4048-44c2-83fb-8a28d8d76b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = f'data_backup/m2_mds_2024-05-31/inference/'\n",
    "if output_dir.split('/')[-2] not in os.listdir('/'.join(output_dir.split('/')[:-2])):\n",
    "    os.makedirs(output_dir)\n",
    "text_file = open(output_dir+'output.txt','w')\n",
    "# text_file = open(output_dir+'output.txt','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mds_features_model2 import *\n",
    "from mds_labs_model2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDSHIFT_CREDENTIALS = json.load(open('../secrets/dtu_redshift_credentials.json', 'r'))\n",
    "dtu = DataTransferUtility(df_mode='pandas', **REDSHIFT_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca574af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# biomarker_schemas = {'Lung':'c3_gn360_202312_nsclc',\n",
    "#                      'Breast':'c3_gn360_202309_breast',\n",
    "#                      'Prostate':'c3_gn360_202309_prostate',\n",
    "#                      'Bladder':'c3_gn360_202309_bladder',\n",
    "#                      'Pancreas':'c3_gn360_202309_pancreatic',\n",
    "#                      'Colorectal':'c3_gn360_202309_crc'}\n",
    "\n",
    "biomarker_schemas= {'Bladder':'c3_gn360_202403_bladder',\n",
    "                    'Breast':'c3_gn360_202403_breast',\n",
    "                    'Colorectal':'c3_gn360_202403_crc',\n",
    "                    'NSCLC':'c3_gn360_202403_nsclc',\n",
    "                    'Ovarian':'c3_gn360_202403_ovarian',\n",
    "                    'Pancreas':'c3_gn360_202403_pancreatic',\n",
    "                    'Prostate':'c3_gn360_202403_prostate',\n",
    "                    'SCLC':'c3_gn360_202403_sclc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddaad6-4c72-4de6-869b-f0c7401a906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def _identify_following_month_first_date(month, year):\n",
    "    if month == 12:\n",
    "        cutoff_year = int(year) + 1\n",
    "        cutoff_month = 1\n",
    "    else:\n",
    "        cutoff_year = year\n",
    "        cutoff_month = month + 1\n",
    "\n",
    "    cut_off_date = datetime.datetime(\n",
    "        int(cutoff_year), cutoff_month, 1\n",
    "    )\n",
    "\n",
    "    return cut_off_date\n",
    "\n",
    "\n",
    "def prepare_cutoff_date(schema_name):\n",
    "    current_year = str(date.today()).split(\"-\")[0]\n",
    "    prev_year = str(int(str(date.today()).split(\"-\")[0]) - 1)\n",
    "    if re.search(current_year + r\"(\\d+)\", schema_name):\n",
    "        year = current_year\n",
    "    elif re.search(prev_year + r\"(\\d+)\", schema_name):\n",
    "        year = prev_year\n",
    "    month = int(re.search(year + r\"(\\d+)\", schema_name).group(1))\n",
    "    cut_off_date = _identify_following_month_first_date(month, year)\n",
    "\n",
    "    return (cut_off_date - timedelta(days=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc2198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(schema,index_date_table,lot_table_name, cohort):\n",
    "    feature_dict = {}\n",
    "    cohort_org = copy.deepcopy(cohort)\n",
    "    if cohort in ['NSCLC','SCLC']:\n",
    "        cohort='Lung'\n",
    "    # cond_table = get_condition_table(schema, cohort)\n",
    "    #     pat_ids = list(cond_table.unique())\n",
    "\n",
    "    # index_date_df = get_index_table(index_date_table, cond_table)\n",
    "    # index_date_df = get_index_table_wo_cond(index_date_table)\n",
    "    index_date_df = get_mds_initial_dx_table(initial_dx_table)\n",
    "    index_date_df = index_date_df.rename(columns={'diagnosis_date':'index_date'})\n",
    "    index_date_df = index_date_df[index_date_df[\"index_date\"].notnull()]\n",
    "    print(f\"Index_date : {index_date_df.shape}, unique patients : {index_date_df['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    # cond_table = cond_table.merge(index_date_df[['chai_patient_id','index_date']],on=['chai_patient_id'],how='inner')\n",
    "    cond_table = index_date_df[['chai_patient_id','index_date']]\n",
    "    cond_table = cond_table[cond_table['index_date'].dt.year>2014]\n",
    "    # cond_table = cond_table[cond_table['index_date']>cond_table['diagnosis_date']]\n",
    "    cond_table = cond_table.drop_duplicates(subset=['chai_patient_id','index_date'])\n",
    "    \n",
    "    censored = get_censored_patients(schema, cond_table)\n",
    "    cut_off_date = prepare_cutoff_date(schema)\n",
    "    censored[\"cut_off_date\"] = cut_off_date\n",
    "    censored['last_available_date'] = censored.apply(lambda x:x['cut_off_date'] if (x['cut_off_date']<x['last_available_date']) else x['last_available_date'],axis=1)\n",
    "    print(f\"censored : {censored.shape}, unique patients : {censored['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    cond_table =cond_table.merge(censored,on='chai_patient_id',how='left')\n",
    "    cond_table['duration'] = cond_table.apply(lambda x:(x['last_available_date']-x['index_date']).days,axis=1)\n",
    "    cond_table = cond_table[cond_table['duration']>0]\n",
    "    print(f\"condition : {cond_table.shape}, unique patients : {cond_table['chai_patient_id'].nunique()}\")\n",
    "    cond_table['random_point'] = cond_table.apply(\n",
    "        lambda x: 0 if x['duration'] in [0, 1] else random.randint(1, x['duration'] - 1), axis=1)\n",
    "    # cond_table['random_date'] = cond_table.apply(lambda x:x['index_date']+timedelta(days=x['random_point']),axis=1)\n",
    "    cond_table['random_date'] = pd.Timestamp('2021-07-01')\n",
    "    cond_table = cond_table[(cond_table['index_date']<=cond_table['random_date']) & (cond_table['last_available_date']>cond_table['random_date'])]\n",
    "\n",
    "\n",
    "    lot_table = get_lot_table(lot_table_name, cond_table=cond_table)\n",
    "    cond_table = cond_table.merge(lot_table,on='chai_patient_id',how='left')\n",
    "\n",
    "    cond_table['lot_diff'] = cond_table.apply(lambda x:(x['regimen_end']-x['random_date']).days,axis=1)\n",
    "    cond_table['lot_diff'] = cond_table['lot_diff'].apply(lambda x:np.nan if x<=0 else x)\n",
    "    cond_table = cond_table.sort_values(by=['lot_diff'],ascending=True)\n",
    "    cond_table = cond_table.drop_duplicates(subset=['chai_patient_id'],keep='first')\n",
    "    cond_table['event'] = cond_table['lot_diff'].apply(lambda x:0 if pd.isna(x) else 1)\n",
    "    cond_table['TTE'] = cond_table.apply(lambda x:x['lot_diff'] if (x['event']==1) else (x['last_available_date']-x['random_date']).days,axis=1)\n",
    "\n",
    "    # cond_table['curation'] = cond_table['chai_patient_id'].apply(lambda x:random.randint(0,1))\n",
    "    # print(cond_table['curation'].value_counts())\n",
    "    \n",
    "    cond_table.to_csv(f'{output_dir}cond_table_{cohort_org}_{today_date}_inference.csv')\n",
    "\n",
    "    text_file.write(f\"Cohort : {cohort_org}\")\n",
    "    text_file.write(f\"Label value counts : \\n{cond_table['event'].value_counts()}\\n\\n\")\n",
    "    text_file.write(f\"Duration stats :\\n\")\n",
    "    text_file.write(f\"For event data points (event = 1) : \\n{cond_table[cond_table['event']==1]['duration'].describe()}\\n\\n\")\n",
    "    text_file.write(f\"For censor data points (event = 0) : \\n{cond_table[cond_table['event']==0]['duration'].describe()}\\n\\n\")\n",
    "    text_file.write(f\"TTE stats :\\n\")\n",
    "    text_file.write(f\"For event data points (event = 1) : \\n{cond_table[cond_table['event']==1]['TTE'].describe()}\\n\\n\")\n",
    "    text_file.write(f\"For censor data points (event = 0) : \\n{cond_table[cond_table['event']==0]['TTE'].describe()}\\n\\n\")\n",
    "    cond_table[cond_table['event']==1]['duration'].hist(bins=100)\n",
    "    plt.savefig(f'{output_dir}_duration_event_hist.png')\n",
    "    plt.show()\n",
    "    cond_table[cond_table['event']==0]['duration'].hist(bins=100)\n",
    "    plt.savefig(f'{output_dir}_duration_censor_hist.png')\n",
    "    plt.show()\n",
    "    cond_table[cond_table['event']==1]['TTE'].hist(bins=100)\n",
    "    plt.savefig(f'{output_dir}_tte_event_hist.png')\n",
    "    plt.show()\n",
    "    cond_table[cond_table['event']==0]['TTE'].hist(bins=100)\n",
    "    plt.savefig(f'{output_dir}_tte_censor_hist.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # if cohort in biomarker_schemas:\n",
    "    #     # biomarker_df = get_biomarker(biomarker_schemas[cohort],schema,cond_table,cohort)\n",
    "    #     biomarker_df = get_all_biomarker(biomarker_schemas[cohort],schema,cond_table,cohort)\n",
    "    #     biomarker_df = biomarker_df.drop('line_start',axis=1)\n",
    "    #     feature_dict['biomarker'] = list(biomarker_df.columns)\n",
    "    #     print(f\"Biomarker : {biomarker_df.shape}, unique patients : {biomarker_df['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    # imaging_df = get_imaging(schema, cond_table)\n",
    "    # feature_dict['imaging'] = list(imaging_df.columns)\n",
    "    # print(f\"Imaging : {imaging_df.shape}, unique patients : {imaging_df['chai_patient_id'].nunique()}\")\n",
    "    \n",
    "    # med_df = get_medication(schema, cond_table)\n",
    "    # med_df = med_df.drop('line_start',axis=1)\n",
    "    # feature_dict['Med'] = list(med_df.columns)\n",
    "    # print(f\"med : {med_df.shape}, unique patients : {med_df['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    # conmed_df = get_conmed(schema, cond_table)\n",
    "    # conmed_df = conmed_df.drop('line_start',axis=1)\n",
    "    # feature_dict['ConMed'] = list(conmed_df.columns)\n",
    "    # print(f\"conmed : {conmed_df.shape}, unique patients : {conmed_df['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    stage_df = get_stage(schema, cond_table, cohort)\n",
    "    # stage_df = stage_df.drop(['line_start','stage_date'],axis=1)\n",
    "    feature_dict['Staging'] = list(stage_df.columns)\n",
    "    print(f\"stage : {stage_df.shape}, unique patients : {stage_df['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    # disease_statis_df = get_disease_status(schema, cond_table)\n",
    "    # feature_dict['Disease Statis'] = list(disease_statis_df.columns)\n",
    "    # print(f\"disease_status : {disease_statis_df.shape}, unique patients : {disease_statis_df['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    final_stat_df = get_labs(schema, cond_table)\n",
    "    # final_stat_df = final_stat_df.drop('line_start',axis=1)\n",
    "    feature_dict['Labs'] = list(final_stat_df.columns)\n",
    "    print(f\"lab : {final_stat_df.shape}, unique patients : {final_stat_df['chai_patient_id'].nunique()}\")\n",
    "\n",
    "    final_stat_df = cond_table[['chai_patient_id','TTE','event']].merge(final_stat_df,on=['chai_patient_id'],how='left')\n",
    "\n",
    "    # final_stat_df = final_stat_df.merge(med_df,on=['chai_patient_id'],how='left')\n",
    "    # final_stat_df = final_stat_df.merge(conmed_df,on=['chai_patient_id'],how='left')\n",
    "    #     final_stat_df = final_stat_df.merge(comorb_df,on='chai_patient_id',how='left')\n",
    "    #     final_stat_df = final_stat_df.merge(surgery_df,on=['chai_patient_id', 'line_start'],how='left')\n",
    "\n",
    "    #     final_stat_df = final_stat_df.merge(demographics_df,on=['chai_patient_id', 'line_start'],how='left')\n",
    "    #     final_stat_df = final_stat_df.merge(radiation_df,on=['chai_patient_id'],how='left')\n",
    "    final_stat_df = final_stat_df.merge(stage_df,on=['chai_patient_id'],how='left')\n",
    "    #     final_stat_df = final_stat_df.merge(tumor_exam_df,on=['chai_patient_id', 'line_start'],how='left')\n",
    "    # final_stat_df = final_stat_df.merge(disease_statis_df,on=['chai_patient_id'],how='left')\n",
    "    # if cohort in biomarker_schemas:\n",
    "    #     final_stat_df = final_stat_df.merge(biomarker_df,on=['chai_patient_id'],how='left')\n",
    "    # final_stat_df = final_stat_df.merge(imaging_df,on=['chai_patient_id'],how='left')\n",
    "    #     final_stat_df = final_stat_df.merge(censored,on=['chai_patient_id','line_start'],how='left')\n",
    "    #     final_stat_df['line_duration'] = final_stat_df.apply(lambda x: -x['line_duration'] if x['censored']=='yes' else x['line_duration'], axis=1)\n",
    "    # final_stat_df['censored'] = final_stat_df.apply(lambda x: False if x['censored']==True else True, axis=1)\n",
    "\n",
    "    return final_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d354f1b-bc43-48b5-92e3-1e4ce2ffba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57afd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOT_TABLES = dtu.s3_to_df('s3://c3-dev-model-factory/sai_vinod/sept_2023_pt360_delivery_unified_LOT_COT.json')['Patient360']['standard']\n",
    "# def get_decoded_from_lot_table(lot_table):    \n",
    "#     check = dtu.redshift_to_df(\n",
    "#                             ''' SELECT version_of_model FROM {source_schema}'''.format(source_schema=lot_table))\n",
    "#     secret_key = u'Kizqfoc8KapwPI4STeBfofaA_rV7nZNnbPSxLdT9KSM='\n",
    "#     cipher_suite = Fernet(secret_key.encode('utf-8'))\n",
    "#     a = check['version_of_model'].astype(str).values[1]  # check is LoT/CoT table dataframe\n",
    "#     a = cipher_suite.decrypt((str.encode(a[2:-1])))\n",
    "#     decoded = json.loads(a.decode(\"utf-8\").replace(\"'\", '\"'))\n",
    "#     schema = decoded['source_schema']\n",
    "#     return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8589e6-73d9-4633-a49d-003f89e5ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_details = {'mds' : {'schema' : 'cdm_structured_202402',\n",
    "                            'initial_dx_table' : 'model_factory_dev.initial_dx_date_cdm_structured_202402_v2_5_20240404_1034',\n",
    "                            'lot_table_name' : 'line_of_therapy.mds_rbs_rwd360_cdm_structured_202402_lot_v6_7_20240404_1146'\n",
    "                           }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a91869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dataframes = []\n",
    "# patient_count = []\n",
    "import time\n",
    "\n",
    "for cohort in ['mds']:\n",
    "    start = time.time() \n",
    "    print(cohort)\n",
    "    \n",
    "    schema = table_details[cohort]['schema']\n",
    "    initial_dx_table = table_details[cohort]['initial_dx_table']\n",
    "    lot_table_name = table_details[cohort]['lot_table_name']\n",
    "    features = main(schema, initial_dx_table, lot_table_name, cohort)\n",
    "    # patient_count.append(unique_patients)\n",
    "\n",
    "    dataframes.append(features)\n",
    "    print(time.time()-start)\n",
    "# pickle.dump(dataframes, open('data/features_additional_lines_sept20.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b51a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388eaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame({'cohort':['Pancreas', 'Melanoma', 'Colorectal', 'Prostate', 'Bladder', 'Breast', 'Gastricesophagus', 'HCC', 'Lung', 'Renal'],'pat_count':[1326, 344, 268, 844, 472, 1144, 869, 133, 5900, 689]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "count_df = count_df.sort_values(by='pat_count',ascending=True)\n",
    "plt.barh(count_df['cohort'],count_df['pat_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pat = sum(count_df['pat_count'])\n",
    "print(f'Total patients : {total_pat}')\n",
    "count_df['percentage'] = (count_df['pat_count']*100)/(total_pat)\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = 'Renal'\n",
    "decoded = get_decoded_from_lot_table(LOT_TABLES[cohort]['schema']+'.'+ LOT_TABLES[cohort]['table'])\n",
    "schema = decoded['source_schema']\n",
    "lot_table_name = LOT_TABLES[cohort]['schema']+'.'+LOT_TABLES[cohort]['table']\n",
    "print(schema)\n",
    "print(lot_table_name)\n",
    "print(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf69f03-0bb9-4bff-96b7-baf673ce2943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features,unique_patients = main(schema, lot_table_name, cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba547e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe_list = pickle.load(open('data/features_sept20.pkl', 'rb'))\n",
    "\n",
    "final_data = pd.concat(dataframes).drop_duplicates(subset=['chai_patient_id']).reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = copy.deepcopy(final_stat_df)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5bcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7961e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['chai_patient_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33301143",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data1 = copy.deepcopy(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_pat_list = list(final_data[['chai_patient_id','Complete therapeutic response_wind_0_45',\n",
    " 'Partial therapeutic response_wind_0_45',\n",
    " 'Stable_wind_0_45',\n",
    " 'Tumor progression_wind_0_45',\n",
    " 'Complete therapeutic response_wind_45_180',\n",
    " 'Partial therapeutic response_wind_45_180',\n",
    " 'Stable_wind_45_180',\n",
    " 'Tumor progression_wind_45_180',\n",
    " 'tp53_mutation','CT',\n",
    " 'PET','MRI','Radioisotope']].dropna(how='all')['chai_patient_id'])\n",
    "final_data= final_data[final_data['chai_patient_id'].isin(cohort_pat_list)]\n",
    "final_data = final_data.reset_index().drop('index',axis=1)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b590144-a88d-4400-ab5e-08017f0f35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12907843-2ee1-402c-b728-26b40b01d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_pat_list = list(final_data.drop(['TTE','event'],axis=1).dropna(how='all')['chai_patient_id'])\n",
    "# final_data= final_data[final_data['chai_patient_id'].isin(cohort_pat_list)]\n",
    "# final_data = final_data.reset_index().drop('index',axis=1)\n",
    "# final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgbse import XGBSEKaplanNeighbors\n",
    "# from xgbse._kaplan_neighbors import DEFAULT_PARAMS\n",
    "from xgbse.metrics import concordance_index\n",
    "from xgbse import XGBSEDebiasedBCE\n",
    "from xgbse.converters import convert_to_structured\n",
    "import os\n",
    "import time\n",
    "# medication_df = pickle.load(open('data/medication_df.pkl', 'rb'))\n",
    "\n",
    "# drug_list = pd.read_csv('data/cancer_drugs_public_V13_0.csv')\n",
    "# chemo_drug_list = drug_list[drug_list['primary_category']=='Chemotherapy']\n",
    "# chemo = []\n",
    "# for col in medication_df.columns:\n",
    "#     if col in chemo_drug_list['active_ingredient'].tolist():\n",
    "#         print(col)\n",
    "#         chemo.append(col)\n",
    "# medication_df = medication_df[chemo + ['chai_patient_id', 'line_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e639a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data1[['Complete therapeutic response_wind_0_45',\n",
    "#  'Partial therapeutic response_wind_0_45',\n",
    "#  'Stable_wind_0_45',\n",
    "#  'Tumor progression_wind_0_45',\n",
    "#  'Complete therapeutic response_wind_45_180',\n",
    "#  'Partial therapeutic response_wind_45_180',\n",
    "#  'Stable_wind_45_180',\n",
    "#  'Tumor progression_wind_45_180']].dropna(how='all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed848bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data[['Complete therapeutic response_wind_0_45',\n",
    "#  'Partial therapeutic response_wind_0_45',\n",
    "#  'Stable_wind_0_45',\n",
    "#  'Tumor progression_wind_0_45',\n",
    "#  'Complete therapeutic response_wind_45_180',\n",
    "#  'Partial therapeutic response_wind_45_180',\n",
    "#  'Stable_wind_45_180',\n",
    "#  'Tumor progression_wind_45_180','tp53_mutation','CT',\n",
    "#  'PET',\n",
    "#  'MRI',\n",
    "#  'Radioisotope']].dropna(how='all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_labs = pickle.load(open('mc/lab_features_sept_14_0.pkl', 'rb'))\n",
    "# dataframe_list = pickle.load(open('data/features_sept20.pkl', 'rb'))\n",
    "# final_data = pd.concat(dataframe_list).drop_duplicates().drop(columns = [np.nan], axis = 1)\n",
    "# final_data = pd.concat([final_data, final_data1]).drop_duplicates()\n",
    "# cohort_df = pd.get_dummies(final_data, columns = ['cohort', 'ethnicity', 'gender', 'race'], prefix = None)\n",
    "# cohort_df = cohort_df.drop(np.nan, axis = 1)\n",
    "# drop_these = []\n",
    "# for col in list(cohort_df.columns):\n",
    "#     for s in ['Mean', 'Median_', 'SD_', 'Minimum_', 'slope',\n",
    "#               'Maximum_', 'Skewness_', 'Kurtosis_', '25th_Percentile_', '75th_Percentile_', 'Range_']:\n",
    "#         if col.startswith(s):\n",
    "#             drop_these.append(col)\n",
    "# cohort_df = cohort_df.drop(columns = drop_these, axis = 1)\n",
    "# cohort_df = cohort_df.merge(new_labs, on = ['chai_patient_id', 'line_start'], how = 'left')\n",
    "# X = final_data.drop(['chai_patient_id','last_available_date','line_start','line_end','line_duration','random_point','line_number','target_duration',\n",
    "#                      'censored', 'stage_date'],axis=1)\n",
    "X = final_data.drop(['chai_patient_id','TTE','event'],axis=1)\n",
    "\n",
    "# Y = cohort_df[['line_duration']]\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "X.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X.columns.values]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=348)\n",
    "# y_train['event'] = y_train.apply(lambda x: 1 if x['line_duration']>0 else 0, axis = 1)\n",
    "# y_test['event'] = y_test.apply(lambda x: 1 if x['line_duration']>0 else 0, axis = 1)\n",
    "\n",
    "# y_train_np = y_train.to_records(index=False)\n",
    "# y_train_np = np.array(y_train_np, dtype = y_train_np.dtype.descr)\n",
    "\n",
    "# y_test_np = y_test.to_records(index = False)\n",
    "# y_test_np = np.array(y_test_np, dtype = y_test_np.dtype.descr)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"======================\")\n",
    "# # loop to show different scale results\n",
    "# m = []\n",
    "# for scale in [1.0]:\n",
    "#     start = time.time()\n",
    "#     DEFAULT_PARAMS['aft_loss_distribution_scale'] = scale\n",
    "#     xgbse_model = XGBSEKaplanNeighbors(DEFAULT_PARAMS, n_neighbors=30)\n",
    "#     xgbse_model.fit(X_train, y_train_np)\n",
    "#     m.append(xgbse_model)\n",
    "#     preds = xgbse_model.predict(X_test)\n",
    "#     preds_train = xgbse_model.predict(X_train)\n",
    "#     cind_test = concordance_index(y_test_np, preds)\n",
    "#     cind_train = concordance_index(y_train_np, preds_train)\n",
    "#     print(f\"aft_loss_distribution_scale: {scale}\")\n",
    "#     print(f\"C-index, train: {cind_train:.3f}\")\n",
    "#     print(f\"C-index, test: {cind_test:.3f}\")\n",
    "#     #print(f\"Average probability of survival: {avg_probs}\")\n",
    "#     print(\"----\", time.time() - start)\n",
    "# # pickle.dump(m, open('models/xgbse_models_nlp_sept20_additional_lines.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data['censored']=final_data['censored'].apply(lambda x:False if x==True else True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = convert_to_structured((final_data['TTE']),final_data['event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e24b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b71e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc290e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_list = list(x_train.columns)\n",
    "# len(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'data_backup/column_list_11_28_2023.pkl','wb') as f:\n",
    "#     pickle.dump(column_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_XGB_AFT = {\n",
    "    'objective': 'survival:aft',\n",
    "    'eval_metric': 'aft-nloglik',\n",
    "    'aft_loss_distribution': 'normal',\n",
    "    'aft_loss_distribution_scale': 1.0,\n",
    "    'tree_method': 'hist',\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 16,\n",
    "    'booster':'dart',\n",
    "    'subsample': 0.8,\n",
    "    'min_child_weight': 30,\n",
    "    'colsample_bynode':0.8\n",
    "}\n",
    "\n",
    "xgbse_model = XGBSEDebiasedBCE(PARAMS_XGB_AFT)\n",
    "xgbse_model.fit(x_train,y_train,time_bins=np.array([60,90,120,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893be7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cindex_list = []\n",
    "test_cindex_list = []\n",
    "train_cindex_list.append(concordance_index(y_train, xgbse_model.predict(x_train)))\n",
    "test_cindex_list.append(concordance_index(y_test, xgbse_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train c-index list : {train_cindex_list}')\n",
    "print(f'Test c-index list: {test_cindex_list}')\n",
    "print(f'Train c-index average : {np.mean(train_cindex_list)}')\n",
    "print(f'Test c-index average: {np.mean(test_cindex_list)}')\n",
    "text_file.write(f'Train c-index average : {np.mean(train_cindex_list)} \\n')\n",
    "text_file.write(f'Test c-index average: {np.mean(test_cindex_list)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "pred.append(xgbse_model.predict(x_test))\n",
    "    \n",
    "event_prob_df = 1-pred[0]\n",
    "# event_prob_df.to_csv(f'data_backup/all_feature_prob_{today_date}.csv')\n",
    "text_file.write('Number of patients above 0.8 prediction probability\\n')\n",
    "slelected_pt_list = []\n",
    "for col in event_prob_df.columns:\n",
    "    selected_df = event_prob_df[event_prob_df[col]>=0.8]\n",
    "    main_index = list(x_test.reset_index().iloc[list(selected_df.index)]['index'])\n",
    "    slelected_pt_list.append(list(final_data.iloc[main_index]['chai_patient_id']))\n",
    "    print(f'{col} : {selected_df.shape}')\n",
    "    text_file.write(f'For window {col} : {selected_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93850ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in [60,90,120,150]:\n",
    "    print(f'window : {i}')\n",
    "    event_prob_df[i].hist(bins=100)\n",
    "    plt.savefig(f'{output_dir}predicted_prob_distribution_{i}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d507ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "selcted_patient_info = pd.DataFrame({'chai_patient_id':slelected_pt_list[3]})\n",
    "window =[60,90,120,150]\n",
    "for i in range(len(slelected_pt_list)):\n",
    "    selcted_patient_info[window[i]] = selcted_patient_info['chai_patient_id'].apply(lambda x:True if x in slelected_pt_list[i] else False)\n",
    "\n",
    "selcted_patient_info = selcted_patient_info.merge(final_data,on='chai_patient_id',how='inner') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d426b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import joblib\n",
    "# date = '02_13_2024'\n",
    "# event_prob_df.to_csv(f'{output_dir}event_prob_df_{date}.csv')\n",
    "# x_train.to_csv(f'{output_dir}x_train_{date}.csv')\n",
    "# x_test.to_csv(f'{output_dir}x_test_{date}.csv')\n",
    "# np.save(f'{output_dir}y_train_{date}.npy',y_train)\n",
    "# np.save(f'{output_dir}y_test_{date}.npy',y_test)\n",
    "# final_data.to_csv(f'{output_dir}final_data_{date}.csv')\n",
    "# with open(f'{output_dir}model_{date}.pkl','wb') as f:\n",
    "#     pickle.dump(xgbse_model,f)\n",
    "# joblib.dump(xgbse_model,f'{output_dir}model_{date}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ba95b-4503-4ab0-a879-b364a837de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72958f85-f644-44ea-8af0-1f8588289714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "date = '05_31_2024'\n",
    "# event_prob_df = pd.read_csv(f'{output_dir}event_prob_df_{date}.csv')\n",
    "x_train = pd.read_csv(f'data_backup/m2_mds_2024-05-31/x_train_{date}.csv')\n",
    "# x_test = pd.read_csv(f'{output_dir}x_test_{date}.csv')\n",
    "# y_train = np.load(f'{output_dir}y_train_{date}.npy')\n",
    "# y_test = np.load(f'{output_dir}y_test_{date}.npy')\n",
    "# final_data = pd.read_csv(f'{output_dir}final_data_{date}.csv')\n",
    "\n",
    "with open(f'data_backup/m2_mds_2024-05-31/model_{date}.pkl','rb') as f:\n",
    "    xgbse_model = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bb946-6d13-4cf6-9cc0-ebfd7ab25384",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244967c-a92d-4942-abee-d140876da8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33fb13d-2b31-4d40-8676-b6ab4a5fa52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3c8c6-3711-4dee-87a9-72f954f5663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['Delta_mean_ecog_0_45',\n",
    "       'Delta_min_ecog_0_45', 'Delta_max_ecog_0_45', 'Mean_ecog_0_45',\n",
    "       'Median_ecog_0_45', 'SD_ecog_0_45', 'Minimum_ecog_0_45',\n",
    "       'Maximum_ecog_0_45', 'Skewness_ecog_0_45', 'Kurtosis_ecog_0_45',\n",
    "       '25th_Percentile_ecog_0_45', '75th_Percentile_ecog_0_45',\n",
    "       'Range_ecog_0_45', 'slope_ecog_0_45', 'Delta_mean_ecog_45_180',\n",
    "       'Delta_min_ecog_45_180', 'Delta_max_ecog_45_180', 'Mean_ecog_45_180',\n",
    "       'Median_ecog_45_180', 'SD_ecog_45_180', 'Minimum_ecog_45_180',\n",
    "       'Maximum_ecog_45_180', 'Skewness_ecog_45_180', 'Kurtosis_ecog_45_180',\n",
    "       '25th_Percentile_ecog_45_180', '75th_Percentile_ecog_45_180',\n",
    "       'Range_ecog_45_180', 'slope_ecog_45_180', 'durvalumab', 'afatinib',\n",
    "       'osimertinib', 'pembrolizumab', 'adagrasib', 'docetaxel', 'ceritinib',\n",
    "       'gemcitabine', 'atezolizumab', 'etoposide', 'pemetrexed', 'ipilimumab',\n",
    "       'crizotinib', 'carboplatin', 'sotorasib', 'gefitinib', 'alectinib',\n",
    "       'ramucirumab', 'amivantamab', 'necitumumab', 'brigatinib', 'lorlatinib',\n",
    "       'bevacizumab', 'dacomitinib', 'erlotinib', 'cisplatin', 'paclitaxel',\n",
    "       'mobocertinib', 'nivolumab', 'dexamethasone', 'stage', 'tstage',\n",
    "       'mstage', 'nstage', 'Complete therapeutic response_wind_0_45',\n",
    "       'Partial therapeutic response_wind_0_45', 'Stable_wind_0_45',\n",
    "       'Tumor progression_wind_0_45',\n",
    "       'Complete therapeutic response_wind_45_180',\n",
    "       'Partial therapeutic response_wind_45_180', 'Stable_wind_45_180',\n",
    "       'Tumor progression_wind_45_180', 'biomarker_KRAS', 'biomarker_TP53',\n",
    "       'biomarker_TMB', 'biomarker_PD-L1', 'biomarker_EGFR', 'biomarker_BRAF',\n",
    "       'biomarker_PTEN', 'biomarker_TERT', 'biomarker_KIT', 'biomarker_PIK3CA',\n",
    "       'biomarker_CDH1', 'biomarker_STK11', 'biomarker_ALK', 'CT', 'PET',\n",
    "       'MRI', 'Radioisotope', 'cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103b33d-972c-4cca-8f43-f97a39d0ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15d43f-9781-4a89-85de-5bedef4ad968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[x_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f905d-728a-43d1-9e87-df032efcfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_prob = 1-xgbse_model.predict(X)\n",
    "final_data = pd.concat([final_data,event_prob],axis=1)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48485686-4092-4ecc-8829-0542aa420c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(f'{output_dir}inference_final_data.csv',index=False)\n",
    "# final_data = pd.read_csv(f'{output_dir}inference_final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c610252-a6fb-45cc-a442-321a3146bf98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9510f-08f9-4392-84a9-9c97b0f3fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cc5d9-a9cc-441f-9c3e-3ca1b4c61c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[final_data['event']==0]['TTE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d3c7a-c21c-4824-8846-b0734cc7c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_90['TTE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4964ed-881e-4783-bc8e-b796b3007723",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['event'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e65550-f6c4-412c-bd68-5a9325a5f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_90 = final_data[['chai_patient_id','TTE','event',90]]\n",
    "final_data_90['event_90'] = final_data_90.apply(lambda x:0 if x['TTE']>90 else x['event'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42041e5-7756-4157-8997-c20646d6d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = final_data_90[['chai_patient_id','event_90',90]]\n",
    "pa.columns = ['chai_patient_id','actual','pred']\n",
    "pa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da928de-b1a8-4181-b575-e37451eeb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_90['chai_patient_id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935172f-aa43-439e-b03c-c9565f8b4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_q = pa.copy()\n",
    "pa_q['quantile'] = pd.qcut(pa['pred'],q = 4, labels = False)\n",
    "pa_q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec7b75-9d86-4cae-a2a3-090efba8b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = pd.DataFrame(columns=['quartile','min_prob','max_prob'])\n",
    "for qt in [0,1,2,3]:\n",
    "    probs = probs.append({'quartile':qt,\n",
    "                        'min_prob':pa_q[pa_q['quantile']==qt].pred.min(),\n",
    "                        'max_prob':pa_q[pa_q['quantile']==qt].pred.max()},ignore_index=True)\n",
    "\n",
    "probs.to_csv(f'{output_dir}inference/quartile_min_max_prob.csv',index=False)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c5c59-c666-475a-b161-29ad7c7e2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "for qt in [0,1,2,3]:\n",
    "    actual = pa_q[pa_q['quantile']==qt].actual\n",
    "    pred   = pa_q[pa_q['quantile']==qt].pred\n",
    "    auc    = roc_auc_score(actual,pred)\n",
    "    # print('Quartile:', qt, ' AUC = ',auc)\n",
    "    roc.append(pd.DataFrame({'Quartile':[qt],'AUC':[auc]}))\n",
    "               \n",
    "roc = pd.concat(roc)\n",
    "roc          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30727423-f018-44a0-9bb0-167e775ea292",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_group = pd.DataFrame({'top2_quartiles':roc_auc_score(pa_q[pa_q['quantile']>1].actual, pa_q[pa_q['quantile']>1].pred),\n",
    "                    'top1_quartiles':roc_auc_score(pa_q[pa_q['quantile']>2].actual, pa_q[pa_q['quantile']>2].pred),\n",
    "                    'bottom2_quartiles':roc_auc_score(pa_q[pa_q['quantile']<2].actual, pa_q[pa_q['quantile']<2].pred),\n",
    "                    'full_dataset':roc_auc_score(pa_q.actual, pa_q.pred)}.items())\n",
    "roc_group.columns = ['Quartile','AUC']\n",
    "\n",
    "roc = pd.concat([roc,roc_group])\n",
    "\n",
    "probs.to_csv(f'{output_dir}inference/quartile_auc.csv',index=False)\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56385d16-24e7-4b89-bd6f-56c7cdc667f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.DataFrame(columns=['th','precision','recall'])\n",
    "for th in range(0, 100, 1):\n",
    "    tmp = pa_q[['chai_patient_id','actual','pred']]\n",
    "    tmp['pred_class'] = np.where(tmp.pred>=th/100, 1, 0)\n",
    "    tmp['actual_class'] = tmp.actual\n",
    "    f1 = f1.append({'th':th, \n",
    "                    'precision':precision_score(tmp.actual_class, tmp.pred_class, average='weighted'),\n",
    "                    'recall':recall_score(tmp.actual_class, tmp.pred_class, average='weighted'),\n",
    "                    'f1':f1_score(tmp.actual_class, tmp.pred_class, average = 'weighted')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d783be-e7b1-440d-80ee-7532ee4f8156",
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_plot = f1[['precision','recall','f1']].plot()\n",
    "fig = prf_plot.get_figure()\n",
    "fig.savefig(f'{output_dir}inference/Pr_Re_F1_plot.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68986b74-3f3c-48ac-bd7b-fda44335ecd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a0137-6755-4dea-8825-e37370377ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b88b7-5cd8-4bce-b485-0a3959c8ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(pa_q['actual'], pa_q['pred'], name=\"PA_pan_solid_model\", plot_chance_level=True)\n",
    "plt.title(f'window : 90')\n",
    "plt.legend(loc=(0.4, 0.8))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2186ad-0270-447d-9ef5-55c7ed4017ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852920e4-9430-4db0-a6a9-67d67ae9b265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6fba6-939a-41dd-9d7a-8d1bb7b8911f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91387e-13b3-466b-b532-31753770e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_prob_df = event_prob_df.drop('Unnamed: 0',axis=1)\n",
    "x_test = x_test.drop('Unnamed: 0',axis=1)\n",
    "final_data = final_data.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571897ee-b5bd-4dea-bf85-beefeee34b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[final_data['event']==1]['TTE'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942502fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay,ConfusionMatrixDisplay,confusion_matrix,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "combined_test_info_df = event_prob_df.join(x_test.reset_index()).merge(final_data[['chai_patient_id','TTE','event']].reset_index(),on='index',how='inner')\n",
    "\n",
    "# combined_test_info_df = event_prob_df.join(x_test.reset_index()).merge(final_stat_df.reset_index()[['index','chai_patient_id','label','final_selection']],on='index',how='inner')\n",
    "for i in [60,90,120,150]:\n",
    "    combined_test_info_df[f'final_selection_{i}'] = combined_test_info_df.apply(lambda x: 0 if x['TTE']>i else x['event'],axis=1)\n",
    "    print(combined_test_info_df[f'final_selection_{i}'].value_counts())\n",
    "    print(f\"ROC AUC Score : {roc_auc_score(combined_test_info_df[f'final_selection_{i}'], combined_test_info_df[i])}\")\n",
    "    text_file.write(f'Label counts for window : {i} \\n')\n",
    "    text_file.write(f\"{combined_test_info_df[f'final_selection_{i}'].value_counts()} \\n\\n\")\n",
    "    PrecisionRecallDisplay.from_predictions(combined_test_info_df[f'final_selection_{i}'], combined_test_info_df[i], name=\"PA_model\", plot_chance_level=True)\n",
    "    plt.title(f'window : {i}')\n",
    "    plt.legend(loc=(0.5, 0.8))\n",
    "    plt.savefig(f'{output_dir}/PRC_Window_{i}.png')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f77509",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame(xgbse_model.feature_importances_.items(),columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df =feature_importance_df.sort_values(by='importance',ascending=False)\n",
    "combine_feature_importance_df_subset = feature_importance_df[:20]\n",
    "combine_feature_importance_df_subset = combine_feature_importance_df_subset.sort_values(by='importance',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c22f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20,10))\n",
    "plt.barh(combine_feature_importance_df_subset['feature'],combine_feature_importance_df_subset['importance'])\n",
    "# plt.xticks(range(len(combine_feature_importance_df_subset['feature'])), combine_feature_importance_df_subset['average'],rotation='vertical')\n",
    "plt.savefig(f'{output_dir}/importance_plot.png',bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd08d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for window in [60,90,120,150]:\n",
    "    combined_test_info_df[combined_test_info_df[f'final_selection_{window}']==True][window].plot.kde()\n",
    "    combined_test_info_df[combined_test_info_df[f'final_selection_{window}']==False][window].plot.kde()\n",
    "    plt.legend(['Event','Censored'])\n",
    "    plt.title(f'Prediction window : {window}')\n",
    "    plt.savefig(f'{output_dir}/pred_prob_classwise_kde_window_{window}.png',bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a439c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\n",
    "# combined_test_info_df = event_prob_df.join(x_test.reset_index()).merge(final_stat_df.reset_index()[['index','chai_patient_id','label','final_selection']],on='index',how='inner')\n",
    "metric_list = []\n",
    "for window in [60,90,120,150]:\n",
    "    window_df = pd.DataFrame({'window':[window]})\n",
    "    for thresold in [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "        combined_test_info_df[f'pred_{thresold}'] = combined_test_info_df[window].apply(lambda x:x>thresold)\n",
    "        cm = confusion_matrix(combined_test_info_df[f'final_selection_{i}'],combined_test_info_df[f'pred_{thresold}'])\n",
    "        tn,fp,fn,tp = cm[0,0],cm[0,1],cm[1,0],cm[1,1]\n",
    "        p1 = tp/(tp+fp)\n",
    "        r1 = tp/(tp+fn)\n",
    "        f1 = 2*p1*r1/(p1+r1)\n",
    "        p0 = tn/(tn+fn)\n",
    "        r0 = tn/(tn+fp)\n",
    "        f0 = 2*p0*r0/(p0+r0)\n",
    "        window_df = pd.concat([window_df,pd.DataFrame({\n",
    "            f'tn_{thresold}' : [tn],\n",
    "            f'fp_{thresold}' : [fp],\n",
    "            f'fn_{thresold}' : [fn],\n",
    "            f'tp_{thresold}' : [tp],\n",
    "            f'p1_{thresold}' : [p1],\n",
    "            f'r1_{thresold}' : [r1],\n",
    "            f'f1_{thresold}' : [f1],\n",
    "            f'p0_{thresold}' : [p0],\n",
    "            f'r0_{thresold}' : [r0],\n",
    "            f'f0_{thresold}' : [f0],\n",
    "        })],axis=1)\n",
    "    metric_list.append(window_df)\n",
    "metric_df = pd.concat(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fd856",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90349e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "x_train_sample =  x_train.sample(n=200,random_state=123).astype('float64')\n",
    "explainer = shap.Explainer(xgbse_model.predict,x_train_sample)\n",
    "shap_values = explainer(x_train_sample,max_evals='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885cfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file.plots.beeswarm(shap_values[:,:,0],max_display=30)\n",
    "plt.savefig(f'{output_dir}/shap_plot.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b034dcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
